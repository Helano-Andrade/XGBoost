{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÓDIGO 1.1)\n",
    "\n",
    "import pandas as pd # Biblioteca para manipulação de dados.\n",
    "import matplotlib.pyplot as plt # Bibliotecas para visualização de dados.\n",
    "import seaborn as sns # Bibliotecas para visualização de dados.\n",
    "from xgboost import XGBRegressor # Classe do XGBoost para tarefas de regressão.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score # Função para realizar validação cruzada.\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error# Função para calcular o erro quadrático médio.\n",
    "import numpy as np # Biblioteca para operações matemáticas adicionais.\n",
    "\n",
    "\n",
    "# Carrega o dataset do caminho especificado usando pandas.\n",
    "dataset_path = '/content/Jubarte_SEx_Ex_Ez_EW01_2002_Poly3_AI_MCD_5_5_6_0_14_0.csv' # AMPMOD , PHASEMOD\n",
    "#dataset_path = '/content/rotated_dataset5.csv' # REAL E IMAGINARIO\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "\n",
    "data = data[['AmpMod', 'PhaseMod', 'Freq']] # COLUNAS SELECIONADAS (AmpMod, PhaseMod, Frequencia)\n",
    "#data = data[['AmpMod', 'PhaseMod', 'Offset', 'Freq']] # COLUNAS SELECIONADAS ( AmpMod, PhaseMod, Offset, Frequencia)\n",
    "#data = data[['Real', 'Imaginario', 'Freq']] # COLUNAS SELECIONADAS ( Real, Imaginario, Frequencia)\n",
    "\n",
    "\n",
    "X = data[['AmpMod', 'PhaseMod']]  # Features -  (AmpMod e PhaseMod).\n",
    "#X = data[['AmpMod', 'PhaseMod', 'Offset']]  # Features -  (AmpMod , PhaseMod , Offset).\n",
    "#X = data[['Real', 'Imaginario']]  # Features -  (Real , Imaginario).\n",
    "y = data['Freq']                  # Target - (Freq).\n",
    "\n",
    "# Divisão em conjuntos de treino (80%) e teste (20%), # shuffle=True embaralha os dados antes de dividir.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "model = XGBRegressor(random_state=42) # Inicializa o modelo de regressão do XGBoost.\n",
    "\n",
    "# Treina o modelo XGBRegressor com os dados de treino.\n",
    "model.fit(X_train, y_train) # Treina o modelo usando os dados de treino (X_train e y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,2 , figsize=(15, 8))\n",
    "\n",
    "ax[0].plot(y_test.values[:100], label='Real')\n",
    "ax[0].plot(y_pred[:100], label='Predito')\n",
    "ax[0].set_xlabel('Amostras')\n",
    "ax[0].set_ylabel('Frequência')\n",
    "\n",
    "ax[1].hist(y_test.values, label='Real')\n",
    "ax[1].hist(y_pred, label='Predito', fill=False)\n",
    "ax[1].set_xlabel('Amostras')\n",
    "ax[1].set_ylabel('Frequência')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o erro quadrático médio (MSE) das previsões.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calcula o erro quadrático médio (RMSE) das previsões.\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a importância das features.\n",
    "feature_importances = model.feature_importances_\n",
    "features = ['AmpMod', 'PhaseMod']\n",
    "\n",
    "# Exibindo a importância das features no console\n",
    "print(\"Importância das features:\")\n",
    "for name, val in zip(features, feature_importances):\n",
    "    print(f'{name}: {val:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a importância das features.\n",
    "feature_importances = model.feature_importances_\n",
    "#features = ['AmpMod', 'PhaseMod', 'Offset']\n",
    "features = ['AmpMod', 'PhaseMod']\n",
    "#features = ['Real', 'Imaginario']\n",
    "\n",
    "# Cria um DataFrame para a visualização.\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Ordena o DataFrame pela importância das features.\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plota a importância das features.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='rainbow')\n",
    "plt.title('Importância das Features')\n",
    "plt.xlabel('Importância')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Realiza a validação cruzada k-fold com 5 folds.\n",
    "kfold = 5\n",
    "cv_results = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Converte os resultados para valores positivos e calcula a média.\n",
    "cv_mse = np.mean(np.abs(cv_results))\n",
    "cv_rmse = np.sqrt(cv_mse)\n",
    "\n",
    "print(f\"Cross-Validation MSE (mean): {cv_mse}\")\n",
    "print(f\"Cross-Validation RMSE (mean): {cv_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Inicializar os modelos\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Treinar e prever com RandomForest\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Treinar e prever com LinearRegression\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho de ambos os modelos\n",
    "for model_name, pred in zip(['XGBoost', 'RandomForest', 'LinearRegression'], [y_pred, rf_y_pred, lr_y_pred]):\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"{model_name} - MSE: {mse}, MAE: {mae}, R²: {r2}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Prever novamente com os diferentes modelos para obter todos os erros\n",
    "y_pred_xgb = model.predict(X_test)  # Previsões do modelo XGBoost\n",
    "y_pred_rf = rf_model.predict(X_test)  # Previsões do modelo RandomForest\n",
    "y_pred_lr = lr_model.predict(X_test)  # Previsões do modelo LinearRegression\n",
    "\n",
    "# Calcular os erros absolutos (diferenças entre valores reais e previstos) para cada modelo\n",
    "errors_xgb = np.abs(y_test - y_pred_xgb)\n",
    "errors_rf = np.abs(y_test - y_pred_rf)\n",
    "errors_lr = np.abs(y_test - y_pred_lr)\n",
    "\n",
    "# Realizar o teste de Wilcoxon entre XGBoost e RandomForest\n",
    "stat, p_value_xgb_rf = wilcoxon(errors_xgb, errors_rf)\n",
    "print(f\"Wilcoxon test between XGBoost and RandomForest: p-value = {p_value_xgb_rf}\")\n",
    "\n",
    "# Realizar o teste de Wilcoxon entre XGBoost e LinearRegression\n",
    "stat, p_value_xgb_lr = wilcoxon(errors_xgb, errors_lr)\n",
    "print(f\"Wilcoxon test between XGBoost and LinearRegression: p-value = {p_value_xgb_lr}\")\n",
    "\n",
    "# Realizar o teste de Wilcoxon entre RandomForest e LinearRegression\n",
    "stat, p_value_rf_lr = wilcoxon(errors_rf, errors_lr)\n",
    "print(f\"Wilcoxon test between RandomForest and LinearRegression: p-value = {p_value_rf_lr}\")\n",
    "\n",
    "# Interpretação dos resultados\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretação dos resultados:\")\n",
    "if p_value_xgb_rf < alpha:\n",
    "    print(\"Diferença entre XGBoost e RandomForest é estatisticamente significativa.\")\n",
    "else:\n",
    "    print(\"Diferença entre XGBoost e RandomForest não é estatisticamente significativa.\")\n",
    "\n",
    "if p_value_xgb_lr < alpha:\n",
    "    print(\"Diferença entre XGBoost e LinearRegression é estatisticamente significativa.\")\n",
    "else:\n",
    "    print(\"Diferença entre XGBoost e LinearRegression não é estatisticamente significativa.\")\n",
    "\n",
    "if p_value_rf_lr < alpha:\n",
    "    print(\"Diferença entre RandomForest e LinearRegression é estatisticamente significativa.\")\n",
    "else:\n",
    "    print(\"Diferença entre RandomForest e LinearRegression não é estatisticamente significativa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
